{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e192d2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/06 16:03:10 INFO mlflow.tracking.fluent: Experiment with name 'my-genai-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/470252759051174371', creation_time=1751806990835, experiment_id='470252759051174371', last_update_time=1751806990835, lifecycle_stage='active', name='my-genai-experiment', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Connect to remote MLflow server\n",
    "mlflow.set_tracking_uri(\"http://localhost:5001\")\n",
    "mlflow.set_experiment(\"my-genai-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32fab602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: http://127.0.0.1:5001\n",
      "Active Experiment: <Experiment: artifact_location='mlflow-artifacts:/470252759051174371', creation_time=1751806990835, experiment_id='470252759051174371', last_update_time=1751806990835, lifecycle_stage='active', name='my-genai-experiment', tags={}>\n",
      "‚úì Successfully connected to MLflow!\n",
      "üèÉ View run clumsy-sloth-149 at: http://127.0.0.1:5001/#/experiments/0/runs/86408a8d6c2f467792befbc99348f5ef\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Print connection information\n",
    "print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Active Experiment: {mlflow.get_experiment_by_name('my-genai-experiment')}\")\n",
    "\n",
    "# Test logging\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"test_param\", \"test_value\")\n",
    "    print(\"‚úì Successfully connected to MLflow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4df8574e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At the beginning of your Python script\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea73610c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-Rxx5LwjUXxhDSkdcgZYsaA'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ.get('OPENAI_BASE_URL', 'Not set')\n",
    "os.environ.get('OPENAI_API_KEY', 'Not set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f7e5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    base_url=os.getenv('OPENAI_BASE_URL')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d098248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=65eea03257774347b6095651eabd579f&amp;experiment_id=0&amp;version=3.1.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=65eea03257774347b6095651eabd579f)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is MLflow?\",\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6f5b1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MLflow is an open-source platform designed to manage the complete machine learning (ML) lifecycle. It aims to streamline the process of developing, deploying, and managing machine learning models. MLflow provides capabilities for tracking experiments, packaging code into reproducible runs, deploying models to various environments, and sharing models.\\n\\nMLflow consists of four main components:\\n\\n1. **MLflow Tracking**: This component allows users to log and query experiments, including parameters, metrics, and artifacts produced during the model training process. It helps data scientists keep track of their experiments and compare different runs to identify the best-performing models.\\n\\n2. **MLflow Projects**: MLflow Projects provide a standardized way to package data science code in a reusable format. It allows users to define an environment and dependencies, making it easier for others to reproduce their work.\\n\\n3. **MLflow Models**: This component is responsible for managing and serving machine learning models in various formats. MLflow Models supports multiple frameworks (like TensorFlow, PyTorch, Scikit-learn, and many others), allowing users to save and deploy models regardless of the underlying technology.\\n\\n4. **MLflow Registry**: The model registry is a centralized store for managing and versioning machine learning models. It provides functionalities for model lifecycle management, including versioning, stage transitions (such as staging, production, archived), and annotations.\\n\\nMLflow is designed to work with any machine learning libraries and can be integrated into various environments, from local development to cloud services. Its extensible architecture allows users to build plugins and integrate it with other tools in their machine learning pipeline, making it a valuable asset for data scientists, machine learning engineers, and organizations working on ML projects.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=b568bf1439614c91bd2b7dcbe77016f4&amp;experiment_id=0&amp;version=3.1.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=b568bf1439614c91bd2b7dcbe77016f4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Set the MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n",
    "\n",
    "# Enable MLflow's autologging to instrument your application with Tracing\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Create an OpenAI client\n",
    "client = openai.OpenAI()\n",
    "\n",
    "\n",
    "# Use the trace decorator to capture the application's entry point\n",
    "@mlflow.trace\n",
    "def my_app(input: str):\n",
    "    # This call is automatically instrumented by `mlflow.openai.autolog()`\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": input,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "my_app(input=\"What is MLflow?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df110d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
