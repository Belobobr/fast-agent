{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFLOW\n",
    "\n",
    "# Track Application Versions with Externally Managed Code\n",
    "# This guide demonstrates MLflow's primary approach for versioning GenAI applications when your core application code resides \n",
    "# in an external version control system (VCS) like Git. In this workflow, an MLflow LoggedModel acts as a metadata hub, \n",
    "# linking a conceptual application version to its specific external code (e.g., a Git commit), configurations, \n",
    "# and associated MLflow entities like traces and evaluation results.\n",
    "\n",
    "# The mlflow.set_active_model() function is key to this process, establishing a context so that subsequent traces and\n",
    "# evaluations are automatically associated with the correct application version.\n",
    "\n",
    "\n",
    "# Models from code makes model transfering repducable between environments...\n",
    "# https://mlflow.org/docs/latest/ml/model/models-from-code/\n",
    "\n",
    "\n",
    "# DATABRIKS\n",
    "\n",
    "# In reality looks like we should be able to log agents\n",
    "# https://docs.databricks.com/aws/en/generative-ai/agent-framework/log-agent \n",
    "\n",
    "# Code-based logging\n",
    "# Databricks recommends using MLflow's Models from Code functionality when logging agents.\n",
    "\n",
    "# In this approach, the agent's code is captured as a Python file, and the Python environment is captured as a list of packages.\n",
    "# ' When the agent is deployed, the Python environment is restored, and the agent's code is executed to load the agent into memory \n",
    "# so it can be invoked when the endpoint is called.\n",
    "\n",
    "# You can couple this approach with the use of pre-deployment validation APIs like mlflow.models.predict() to ensure \n",
    "# that the agent runs reliably when deployed for serving.\n",
    "\n",
    "# To see an example of code-based logging, see ChatAgent authoring example notebooks.\n",
    "\n",
    "# CODE BASED LOGGING\n",
    "# The following instructions and code sample show you how to log an agent with LangChain.\n",
    "\n",
    "# Create a notebook or Python file with your code. For this example, the notebook or file is named agent.py. The notebook or file must contain a LangChain agent, referred to here as lc_agent.\n",
    "\n",
    "# Include mlflow.models.set_model(lc_agent) in the notebook or file.\n",
    "\n",
    "# Create a new notebook to serve as the driver notebook (called driver.py in this example).\n",
    "\n",
    "# In the driver notebook, use the following code to run agent.py and log the results to an MLflow model:\n",
    "\n",
    "# Python\n",
    "# mlflow.langchain.log_model(lc_model=\"/path/to/agent.py\", resources=list_of_databricks_resources)\n",
    "\n",
    "# The resources parameter declares Databricks-managed resources needed to serve the agent, such as a vector search index or serving endpoint that serves a foundation model. For more information, see Authentication for Databricks resources.\n",
    "\n",
    "# Deploy the model. See Deploy an agent for generative AI applications.\n",
    "\n",
    "# When the serving environment is loaded, agent.py is executed.\n",
    "\n",
    "# When a serving request comes in, lc_agent.invoke(...) is called.\n",
    "\n",
    "# import mlflow\n",
    "\n",
    "# code_path = \"/Workspace/Users/first.last/agent.py\"\n",
    "# config_path = \"/Workspace/Users/first.last/config.yml\"\n",
    "\n",
    "# # Input example used by MLflow to infer Model Signature\n",
    "# input_example = {\n",
    "#   \"messages\": [\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": \"What is Retrieval-augmented Generation?\",\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "\n",
    "# # example using langchain\n",
    "# with mlflow.start_run():\n",
    "#   logged_agent_info = mlflow.langchain.log_model(\n",
    "#     lc_model=code_path,\n",
    "#     model_config=config_path, # If you specify this parameter, this configuration is used by agent code. The development_config is overwritten.\n",
    "#     artifact_path=\"agent\", # This string is used as the path inside the MLflow model where artifacts are stored\n",
    "#     input_example=input_example, # Must be a valid input to the agent\n",
    "#     example_no_conversion=True, # Required\n",
    "#   )\n",
    "\n",
    "# print(f\"MLflow Run: {logged_agent_info.run_id}\")\n",
    "# print(f\"Model URI: {logged_agent_info.model_uri}\")\n",
    "\n",
    "# # To verify that the model has been logged correctly, load the agent and call `invoke`:\n",
    "# model = mlflow.langchain.load_model(logged_agent_info.model_uri)\n",
    "# model.invoke(example)\n",
    "\n",
    "\n",
    "# REGISTER IN UNITY CATALOG\n",
    "\n",
    "# import mlflow\n",
    "\n",
    "# mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# catalog_name = \"test_catalog\"\n",
    "# schema_name = \"schema\"\n",
    "# model_name = \"agent_name\"\n",
    "\n",
    "# model_name = catalog_name + \".\" + schema_name + \".\" + model_name\n",
    "# uc_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=model_name)\n",
    "\n",
    "\n",
    "# DEPLOY TO SERVING FROM UNITY CATALOG\n",
    "\n",
    "# from databricks.agents import list_deployments, get_deployments, delete_deployment\n",
    "\n",
    "# # Print all current deployments\n",
    "# deployments = list_deployments()\n",
    "# print(deployments)\n",
    "\n",
    "# # Get the deployment for a specific agent model name and version\n",
    "# agent_model_name = \"\"  # Set to your Unity Catalog model name\n",
    "# agent_model_version = 1  # Set to your agent model version\n",
    "# deployment = get_deployments(model_name=agent_model_name, model_version=agent_model_version)\n",
    "\n",
    "# # Delete an agent deployment\n",
    "# delete_deployment(model_name=agent_model_name, model_version=agent_model_version)\n",
    "\n",
    "# CHAT API ON DATABRICKS\n",
    "# https://docs.databricks.com/aws/en/generative-ai/agent-framework/chat-app\n",
    "\n",
    "# CHAT agent examples\n",
    "# https://docs.databricks.com/aws/en/generative-ai/agent-framework/author-agent#chatagent-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2155267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import mlflow\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    base_url=os.getenv('OPENAI_BASE_URL')\n",
    ")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9dcf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/06 20:52:51 INFO mlflow.tracking.fluent: Experiment with name 'my-genai-app' does not exist. Creating a new experiment.\n",
      "2025/07/06 20:52:51 INFO mlflow.tracking.fluent: LoggedModel with name 'customer_support_agent-48c87a7e' does not exist, creating one...\n",
      "2025/07/06 20:52:51 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-d11b143371234fa88bbef6241591eee3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=1b0c05e6f07c47a59398a02aa09cb7e2&amp;experiment_id=856407723531756817&amp;trace_id=94aa2b09dbb54bbcb37e86a7aed1a5e9&amp;experiment_id=856407723531756817&amp;trace_id=0f5e8ed5a75840b4b3b048a7d64020db&amp;experiment_id=856407723531756817&amp;trace_id=6bff116d2dfe4d07b8fe2678a029daf5&amp;experiment_id=856407723531756817&amp;trace_id=c076cf6dd32c4871a122e6835748e0a1&amp;experiment_id=856407723531756817&amp;version=3.1.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=1b0c05e6f07c47a59398a02aa09cb7e2), Trace(trace_id=94aa2b09dbb54bbcb37e86a7aed1a5e9), Trace(trace_id=0f5e8ed5a75840b4b3b048a7d64020db), Trace(trace_id=6bff116d2dfe4d07b8fe2678a029daf5), Trace(trace_id=c076cf6dd32c4871a122e6835748e0a1)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import openai\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# Configure MLflow Tracking\n",
    "mlflow.set_experiment(\"my-genai-app\")\n",
    "\n",
    "# Get current git commit hash\n",
    "git_commit = (\n",
    "    subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]).decode(\"ascii\").strip()[:8]\n",
    ")\n",
    "\n",
    "# Define your application version using the git commit\n",
    "app_name = \"customer_support_agent\"\n",
    "logged_model_name = f\"{app_name}-{git_commit}\"\n",
    "\n",
    "# Set the active model context - traces will be linked to this\n",
    "mlflow.set_active_model(name=logged_model_name)\n",
    "\n",
    "# Enable autologging for OpenAI, which automatically logs traces\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define and test your agent code - traces are automatically linked\n",
    "client = openai.OpenAI()\n",
    "questions = [\n",
    "    \"How do I reset my password?\",\n",
    "    \"What are your business hours?\",\n",
    "    \"Can I get a refund for my last order?\",\n",
    "    \"Where can I find the user manual for product model number 15869?\",\n",
    "    \"I'm having trouble with the payment page, can you help?\",\n",
    "]\n",
    "for question in questions:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": question}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48931fef",
   "metadata": {},
   "source": [
    "# PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a81e919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/06 20:57:50 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for prompt version to finish creation. Prompt name: chatbot_prompt, version 1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "system_prompt = mlflow.genai.register_prompt(\n",
    "    name=\"chatbot_prompt\",\n",
    "    template=\"You are a chatbot that can answer questions about IT. Answer this question: {{question}}\",\n",
    "    commit_message=\"Initial version of chatbot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e997ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a chatbot that can answer questions about IT. Answer this question: {question}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt.to_single_brace_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2121061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. It allows data scientists and machine learning engineers to track and reproduce experiments, package and share models, and deploy models into production. MLflow supports multiple programming languages and integrates with popular machine learning libraries and frameworks.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=e0ef28b76c034b4aa00f92a0c0c426e2&amp;experiment_id=856407723531756817&amp;version=3.1.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=e0ef28b76c034b4aa00f92a0c0c426e2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Convert MLflow prompt to LangChain format\n",
    "prompt = ChatPromptTemplate.from_template(system_prompt.to_single_brace_format())\n",
    "\n",
    "# Build the chain: prompt → LLM → output parser\n",
    "chain = prompt | ChatOpenAI(temperature=0.7) | StrOutputParser()\n",
    "\n",
    "# Test the chain\n",
    "question = \"What is MLflow?\"\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d25a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/06 21:20:25 INFO mlflow.tracking.fluent: LoggedModel with name 'langchain_model' does not exist, creating one...\n",
      "2025/07/06 21:20:25 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-70c4cd6d38504188ae1a06af880d171f\n"
     ]
    }
   ],
   "source": [
    "# Set the active model for linking traces\n",
    "mlflow.set_active_model(name=\"langchain_model\")\n",
    "\n",
    "# Enable autologging - all traces will be automatically linked to the active model\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb26f6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>trace</th>\n",
       "      <th>client_request_id</th>\n",
       "      <th>state</th>\n",
       "      <th>request_time</th>\n",
       "      <th>execution_duration</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>trace_metadata</th>\n",
       "      <th>tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8fd73ef223ee4065b3ed01f504f9f1ad</td>\n",
       "      <td>Trace(trace_id=8fd73ef223ee4065b3ed01f504f9f1ad)</td>\n",
       "      <td>None</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1751826058353</td>\n",
       "      <td>1821</td>\n",
       "      <td>{'question': 'What are user-defined functions ...</td>\n",
       "      <td>User-defined functions (UDFs) are functions cr...</td>\n",
       "      <td>{'mlflow.trace.tokenUsage': '{\"input_tokens\": ...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'mlflow-artifacts:...</td>\n",
       "      <td>[{'trace_id': 'kn84i4hifs5+Ue+H5JGl5A==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>948563b499104315892b22b44d1b5735</td>\n",
       "      <td>Trace(trace_id=948563b499104315892b22b44d1b5735)</td>\n",
       "      <td>None</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1751826056547</td>\n",
       "      <td>1793</td>\n",
       "      <td>{'question': 'What is Unity Catalog?'}</td>\n",
       "      <td>Unity Catalog is a centralized repository of s...</td>\n",
       "      <td>{'mlflow.trace.tokenUsage': '{\"input_tokens\": ...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'mlflow-artifacts:...</td>\n",
       "      <td>[{'trace_id': 'KwC+YCLIpMpKrkWYezdBtA==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f450a3d985eb448698ed689d902d72c6</td>\n",
       "      <td>Trace(trace_id=f450a3d985eb448698ed689d902d72c6)</td>\n",
       "      <td>None</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1751826053143</td>\n",
       "      <td>3381</td>\n",
       "      <td>{'question': 'What is MLflow Tracking and how ...</td>\n",
       "      <td>MLflow Tracking is a component of the open-sou...</td>\n",
       "      <td>{'mlflow.trace.tokenUsage': '{\"input_tokens\": ...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'mlflow-artifacts:...</td>\n",
       "      <td>[{'trace_id': 'nk02si9JxsTk9KUS1sVqpg==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           trace_id  \\\n",
       "0  8fd73ef223ee4065b3ed01f504f9f1ad   \n",
       "1  948563b499104315892b22b44d1b5735   \n",
       "2  f450a3d985eb448698ed689d902d72c6   \n",
       "\n",
       "                                              trace client_request_id  \\\n",
       "0  Trace(trace_id=8fd73ef223ee4065b3ed01f504f9f1ad)              None   \n",
       "1  Trace(trace_id=948563b499104315892b22b44d1b5735)              None   \n",
       "2  Trace(trace_id=f450a3d985eb448698ed689d902d72c6)              None   \n",
       "\n",
       "           state   request_time  execution_duration  \\\n",
       "0  TraceState.OK  1751826058353                1821   \n",
       "1  TraceState.OK  1751826056547                1793   \n",
       "2  TraceState.OK  1751826053143                3381   \n",
       "\n",
       "                                             request  \\\n",
       "0  {'question': 'What are user-defined functions ...   \n",
       "1             {'question': 'What is Unity Catalog?'}   \n",
       "2  {'question': 'What is MLflow Tracking and how ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  User-defined functions (UDFs) are functions cr...   \n",
       "1  Unity Catalog is a centralized repository of s...   \n",
       "2  MLflow Tracking is a component of the open-sou...   \n",
       "\n",
       "                                      trace_metadata  \\\n",
       "0  {'mlflow.trace.tokenUsage': '{\"input_tokens\": ...   \n",
       "1  {'mlflow.trace.tokenUsage': '{\"input_tokens\": ...   \n",
       "2  {'mlflow.trace.tokenUsage': '{\"input_tokens\": ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  {'mlflow.artifactLocation': 'mlflow-artifacts:...   \n",
       "1  {'mlflow.artifactLocation': 'mlflow-artifacts:...   \n",
       "2  {'mlflow.artifactLocation': 'mlflow-artifacts:...   \n",
       "\n",
       "                                               spans assessments  \n",
       "0  [{'trace_id': 'kn84i4hifs5+Ue+H5JGl5A==', 'spa...          []  \n",
       "1  [{'trace_id': 'KwC+YCLIpMpKrkWYezdBtA==', 'spa...          []  \n",
       "2  [{'trace_id': 'nk02si9JxsTk9KUS1sVqpg==', 'spa...          []  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5001/static-files/lib/notebook-trace-renderer/index.html?trace_id=f450a3d985eb448698ed689d902d72c6&amp;experiment_id=856407723531756817&amp;trace_id=948563b499104315892b22b44d1b5735&amp;experiment_id=856407723531756817&amp;trace_id=8fd73ef223ee4065b3ed01f504f9f1ad&amp;experiment_id=856407723531756817&amp;version=3.1.1\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=f450a3d985eb448698ed689d902d72c6), Trace(trace_id=948563b499104315892b22b44d1b5735), Trace(trace_id=8fd73ef223ee4065b3ed01f504f9f1ad)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questions = [\n",
    "    {\"question\": \"What is MLflow Tracking and how does it work?\"},\n",
    "    {\"question\": \"What is Unity Catalog?\"},\n",
    "    {\"question\": \"What are user-defined functions (UDFs)?\"},\n",
    "]\n",
    "outputs = []\n",
    "\n",
    "for question in questions:\n",
    "    outputs.append(chain.invoke(question))\n",
    "\n",
    "# Verify traces are linked to the active model\n",
    "active_model_id = mlflow.get_active_model_id()\n",
    "mlflow.search_traces(model_id=active_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546faa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# eval_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"inputs\": questions,\n",
    "#         \"expected_response\": [\n",
    "#             \"\"\"MLflow Tracking is a key component of the MLflow platform designed to record and manage machine learning experiments. It enables data scientists and engineers to log parameters, code versions, metrics, and artifacts in a systematic way, facilitating experiment tracking and reproducibility.\n",
    "\n",
    "# How It Works:\n",
    "\n",
    "# At the heart of MLflow Tracking is the concept of a run, which is an execution of a machine learning code. Each run can log the following:\n",
    "\n",
    "# Parameters: Input variables or hyperparameters used in the model (e.g., learning rate, number of trees). Metrics: Quantitative measures to evaluate the model's performance (e.g., accuracy, loss). Artifacts: Output files like models, datasets, or images generated during the run. Source Code: The version of the code or Git commit hash used. These logs are stored in a tracking server, which can be set up locally or on a remote server. The tracking server uses a backend storage (like a database or file system) to keep a record of all runs and their associated data.\n",
    "\n",
    "# Users interact with MLflow Tracking through its APIs available in multiple languages (Python, R, Java, etc.). By invoking these APIs in the code, you can start and end runs, and log data as the experiment progresses. Additionally, MLflow offers autologging capabilities for popular machine learning libraries, automatically capturing relevant parameters and metrics without manual code changes.\n",
    "\n",
    "# The logged data can be visualized using the MLflow UI, a web-based interface that displays all experiments and runs. This UI allows you to compare runs side-by-side, filter results, and analyze performance metrics over time. It aids in identifying the best models and understanding the impact of different parameters.\n",
    "\n",
    "# By providing a structured way to record experiments, MLflow Tracking enhances collaboration among team members, ensures transparency, and makes it easier to reproduce results. It integrates seamlessly with other MLflow components like Projects and Model Registry, offering a comprehensive solution for managing the machine learning lifecycle.\"\"\",\n",
    "#             \"\"\"Unity Catalog is a feature in Databricks that allows you to create a centralized inventory of your data assets, such as tables, views, and functions, and share them across different teams and projects. It enables easy discovery, collaboration, and reuse of data assets within your organization.\n",
    "\n",
    "# With Unity Catalog, you can:\n",
    "\n",
    "# 1. Create a single source of truth for your data assets: Unity Catalog acts as a central repository of all your data assets, making it easier to find and access the data you need.\n",
    "# 2. Improve collaboration: By providing a shared inventory of data assets, Unity Catalog enables data scientists, engineers, and other stakeholders to collaborate more effectively.\n",
    "# 3. Foster reuse of data assets: Unity Catalog encourages the reuse of existing data assets, reducing the need to create new assets from scratch and improving overall efficiency.\n",
    "# 4. Enhance data governance: Unity Catalog provides a clear view of data assets, enabling better data governance and compliance.\n",
    "\n",
    "# Unity Catalog is particularly useful in large organizations where data is scattered across different teams, projects, and environments. It helps create a unified view of data assets, making it easier to work with data across different teams and projects.\"\"\",\n",
    "#             \"\"\"User-defined functions (UDFs) in the context of Databricks and Apache Spark are custom functions that you can create to perform specific tasks on your data. These functions are written in a programming language such as Python, Java, Scala, or SQL, and can be used to extend the built-in functionality of Spark.\n",
    "\n",
    "# UDFs can be used to perform complex data transformations, data cleaning, or to apply custom business logic to your data. Once defined, UDFs can be invoked in SQL queries or in DataFrame transformations, allowing you to reuse your custom logic across multiple queries and applications.\n",
    "\n",
    "# To use UDFs in Databricks, you first need to define them in a supported programming language, and then register them with the SparkSession. Once registered, UDFs can be used in SQL queries or DataFrame transformations like any other built-in function.\"\"\",\n",
    "#         ],\n",
    "#         \"outputs\": outputs,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# from mlflow.genai.scorers import Correctness, RelevanceToQuery, Guidelines\n",
    "# from mlflow.metrics.genai import answer_correctness\n",
    "\n",
    "# # Run evaluation with GenAI metrics\n",
    "# result = mlflow.genai.evaluate(\n",
    "#     data=eval_df,\n",
    "#     scorers=[\n",
    "#         Correctness(),\n",
    "#         RelevanceToQuery(),\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# # View evaluation results\n",
    "# result.tables[\"eval_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d91f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some issues are here\n",
    "\n",
    "# import mlflow.langchain\n",
    "# import pandas as pd\n",
    "# eval_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"question\": [question['question'] for question in questions],\n",
    "#         \"expected_response\": [\n",
    "#             \"\"\"MLflow Tracking is a key component of the MLflow platform designed to record and manage machine learning experiments. It enables data scientists and engineers to log parameters, code versions, metrics, and artifacts in a systematic way, facilitating experiment tracking and reproducibility.\n",
    "\n",
    "# How It Works:\n",
    "\n",
    "# At the heart of MLflow Tracking is the concept of a run, which is an execution of a machine learning code. Each run can log the following:\n",
    "\n",
    "# Parameters: Input variables or hyperparameters used in the model (e.g., learning rate, number of trees). Metrics: Quantitative measures to evaluate the model's performance (e.g., accuracy, loss). Artifacts: Output files like models, datasets, or images generated during the run. Source Code: The version of the code or Git commit hash used. These logs are stored in a tracking server, which can be set up locally or on a remote server. The tracking server uses a backend storage (like a database or file system) to keep a record of all runs and their associated data.\n",
    "\n",
    "# Users interact with MLflow Tracking through its APIs available in multiple languages (Python, R, Java, etc.). By invoking these APIs in the code, you can start and end runs, and log data as the experiment progresses. Additionally, MLflow offers autologging capabilities for popular machine learning libraries, automatically capturing relevant parameters and metrics without manual code changes.\n",
    "\n",
    "# The logged data can be visualized using the MLflow UI, a web-based interface that displays all experiments and runs. This UI allows you to compare runs side-by-side, filter results, and analyze performance metrics over time. It aids in identifying the best models and understanding the impact of different parameters.\n",
    "\n",
    "# By providing a structured way to record experiments, MLflow Tracking enhances collaboration among team members, ensures transparency, and makes it easier to reproduce results. It integrates seamlessly with other MLflow components like Projects and Model Registry, offering a comprehensive solution for managing the machine learning lifecycle.\"\"\",\n",
    "#             \"\"\"Unity Catalog is a feature in Databricks that allows you to create a centralized inventory of your data assets, such as tables, views, and functions, and share them across different teams and projects. It enables easy discovery, collaboration, and reuse of data assets within your organization.\n",
    "\n",
    "# With Unity Catalog, you can:\n",
    "\n",
    "# 1. Create a single source of truth for your data assets: Unity Catalog acts as a central repository of all your data assets, making it easier to find and access the data you need.\n",
    "# 2. Improve collaboration: By providing a shared inventory of data assets, Unity Catalog enables data scientists, engineers, and other stakeholders to collaborate more effectively.\n",
    "# 3. Foster reuse of data assets: Unity Catalog encourages the reuse of existing data assets, reducing the need to create new assets from scratch and improving overall efficiency.\n",
    "# 4. Enhance data governance: Unity Catalog provides a clear view of data assets, enabling better data governance and compliance.\n",
    "\n",
    "# Unity Catalog is particularly useful in large organizations where data is scattered across different teams, projects, and environments. It helps create a unified view of data assets, making it easier to work with data across different teams and projects.\"\"\",\n",
    "#             \"\"\"User-defined functions (UDFs) in the context of Databricks and Apache Spark are custom functions that you can create to perform specific tasks on your data. These functions are written in a programming language such as Python, Java, Scala, or SQL, and can be used to extend the built-in functionality of Spark.\n",
    "\n",
    "# UDFs can be used to perform complex data transformations, data cleaning, or to apply custom business logic to your data. Once defined, UDFs can be invoked in SQL queries or in DataFrame transformations, allowing you to reuse your custom logic across multiple queries and applications.\n",
    "\n",
    "# To use UDFs in Databricks, you first need to define them in a supported programming language, and then register them with the SparkSession. Once registered, UDFs can be used in SQL queries or DataFrame transformations like any other built-in function.\"\"\",\n",
    "#         ]\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# from mlflow.metrics.genai import answer_correctness\n",
    "\n",
    "# with mlflow.start_run() as run:\n",
    "#     # system_prompt = \"Answer the following question in two sentences\"\n",
    "#     # Wrap \"gpt-4\" as an MLflow model.\n",
    "#     logged_model_info = mlflow.langchain.log_model(\n",
    "#         lc_model=chain,\n",
    "#         # task=openai.chat.completions,\n",
    "#         name=\"langchain_model\",\n",
    "#         # messages=[\n",
    "#         #     {\"role\": \"system\", \"content\": system_prompt},\n",
    "#         #     {\"role\": \"user\", \"content\": \"{question}\"},\n",
    "#         # ],\n",
    "#     )\n",
    "\n",
    "#     # Use predefined question-answering metrics to evaluate our model.\n",
    "#     results = mlflow.evaluate(\n",
    "#         logged_model_info.model_uri,\n",
    "#         eval_df,\n",
    "#         targets=\"expected_response\",\n",
    "#         model_type=\"question-answering\",\n",
    "#         extra_metrics=[\n",
    "#             answer_correctness(),\n",
    "#             # latency(),\n",
    "#         ],\n",
    "#     )\n",
    "#     print(f\"See aggregated evaluation results below: \\n{results.metrics}\")\n",
    "\n",
    "#     # Evaluation result for each data record is available in `results.tables`.\n",
    "#     eval_table = results.tables[\"eval_results_table\"]\n",
    "#     print(f\"See evaluation table below: \\n{eval_table}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
